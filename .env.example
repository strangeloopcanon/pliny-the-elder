# Example environment for VEI (Virtual Enterprise Internet)
# Copy to .env and adjust values as needed

# OpenAI-compatible SDK routing (optional; used by vei-llm-test / vei-chat)
OPENAI_API_KEY=sk-your_key_here
# If you use a gateway instead of api.openai.com, set the base URL (usually ends with /v1)
OPENAI_BASE_URL=https://your-openai-compatible-gateway/v1

# MCP server configuration
VEI_HOST=127.0.0.1
VEI_PORT=3001
VEI_SEED=42042

# SSE URL for clients/CLIs
VEI_SSE_URL=http://127.0.0.1:3001/sse

# Artifacts and telemetry
# Directory to write trace.jsonl and run artifacts (if set)
VEI_ARTIFACTS_DIR=/abs/path/out
# Optional streaming endpoint for trace entries (best-effort POST)
VEI_TRACE_POST_URL=https://collector.example/trace

# Server autostart behavior
# 0 = allow background autostart (default); 1 = disable background autostart
VEI_DISABLE_AUTOSTART=0

# Scenario selection (one of the following)
# Built-in name
VEI_SCENARIO_NAME=macrocompute_default
# Or provide a JSON file
VEI_SCENARIO_FILE=/abs/path/scenario.json
# Or inline JSON (single line)
VEI_SCENARIO_JSON={"budget_cap_usd": 3200}

# SlackSim policy
VEI_BUDGET_CAP=3500
VEI_SLACK_DERAIL_PCT=0.1
